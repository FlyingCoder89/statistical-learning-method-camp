# 第10章-隐马尔科夫模型-前向算法{docsify-ignore-all}
&emsp;&emsp;本节推导两个公式$\displaystyle \alpha_{t+1}(i)=\left[\sum_{j=1}^N \alpha_t(j)a_{ji} \right] b_i(o_{t+1})$和$\displaystyle P(O|\lambda)=\sum_{i=1}^N \alpha_T(i)$  

## 式10.17的推导
&emsp;&emsp;$\alpha_t(i)$涉及到时刻$t$的观测值$o_1,o_2,\cdots,o_t$以及状态值$q_i$，记作$\alpha_t(i)=P(o_1,o_2,\cdots,o_t,i_t=q_i)$，这里忽略$\lambda$的条件概率。  
&emsp;&emsp;前向算法用来做的就是概率计算，当$\lambda$给定时，观测值$o_1,o_2,\cdots,o_t$出现的概率为$P(o_1,o_2,\cdots,o_T)$，这个概率是边际概率，$P(o_1,o_2,\cdots,o_T, i_T=q_i)$是联合概率，可得$\displaystyle P(o_1,o_2,\cdots,o_T) = \sum_{i=1}^N P(o_1,o_2,\cdots,o_T, i_T=q_i)=\sum_{i=1}^N \alpha_T(i) $，式10.17可证. 

## 式10.16的推导
&emsp;&emsp;最终的目标就是要求出$\alpha_T(1),\alpha_T(2),\cdots,\alpha_T(N)$，前向算法就是从$(\alpha_1(1),\alpha_1(2),\cdots,\alpha_1(N))$推到$(\alpha_2(1),\alpha_2(2),\cdots,\alpha_2(N))$，一直到$(\alpha_T(1),\alpha_T(2),\cdots,\alpha_T(N))$  
&emsp;&emsp;为了区分符号，修改为$\alpha_t(j)=P(o_1,o_2,\cdots,o_t,i_t=q_j)$，根据定义$\alpha_{t+1}(i) = P(o_1,o_2,\cdots,o_t,o_{t+1},i_{t+1}=q_i)$  
根据边际概率和联合概率可得：$$P(o_1,o_2,\cdots,o_t,o_{t+1},i_{t+1}=q_i) = \sum_{j=1}^N P(o_1,o_2,\cdots,o_t,o_{t+1},i_{t+1}=q_i, i_t=q_j)$$将等号右边的式子进行乘法公式拆分：$$\sum_{j=1}^N P(o_1,o_2,\cdots,o_t,o_{t+1},i_{t+1}=q_i, i_t=q_j) = \sum_{j=1}^N P(o_1,o_2,\cdots,o_t, i_t=q_j)P(o_{t+1}|i_{t+1}=q_i)P(i_{t+1}=q_i|i_t=q_j)$$  
根据隐马尔可夫模型：$$P(o_{t+1}|i_{t+1}=q_i)=b_i(o_{t+1}) \\
P(i_{t+1}=q_i|i_t=q_j)=a_{ji} \\
P(o_1,o_2,\cdots,o_t, i_t=q_j)=\alpha_t(j)$$  
$\displaystyle \therefore \sum_{j=1}^N P(o_1,o_2,\cdots,o_t, i_t=q_j)P(o_{t+1}|i_{t+1}=q_i)P(i_{t+1}=q_i|i_t=q_j) = \left[ \sum_{j=1}^N \alpha_t(j) a_{ji}\right] b_i(o_{t+1}) $  
$\displaystyle \therefore \alpha_{t+1}(i) = \left[ \sum_{j=1}^N \alpha_t(j) a_{ji}\right] b_i(o_{t+1})$，式10.16可证.