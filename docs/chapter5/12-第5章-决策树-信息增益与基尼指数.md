# 第5章-决策树-信息增益与基尼指数{docsify-ignore-all}

## 从定性的角度了解熵与基尼指数的含义
根据公式：  
- 熵：$H(x)=-\Sigma p_i \ln p_i$
- 基尼指数：$\displaystyle Gini(p) =\sum_i p_i(t-p_i)$ 

&emsp;&emsp;这两个指标都是衡量一个随机变量的离散程度（混乱程度），提到离散程度，比较熟悉的是方差。  
&emsp;&emsp;例如随机变量样本值为$x_1,x_2,\cdots,x_n$，方差为$\displaystyle \frac{1}{n} \sum_{i=1}^n(x_i-\overline{x})^2$，如果样本中有两个或者多个相同时，另记$x_j$，对于$j$而言，有$n_j$个样本是相同的取值，则方差为$\displaystyle \sum_j \frac{n_j}{n}(x_j - \overline{x})^2$，记$\displaystyle p_j=\frac{n_j}{n}$表示$x_j$对应的样本出现的频率， 方差为 $\displaystyle \sum_j (x_j - \overline{x})^2p_j$，这种形式一般用于$x$是连续的随机变量，或者虽然$x$为离散的随机变量，但是其取值的大小是有一定含义的，所以在衡量这个离散程度时，会考虑$x_j$到其均值的距离，但是对于熵而言，熵衡量的是离散随机变量，这些随机变量取值的大小是没有意义的。  
&emsp;&emsp;所以对于离散随机变量，一般采用熵或者基尼指数来作为衡量离散程度（混乱程度）的指标。

## 混乱程度的理解
&emsp;&emsp;举一个二分类的例子：掷硬币，投掷硬币以$\displaystyle \frac{1}{2}$的概率出现正面，以$\displaystyle \frac{1}{2}$的概率出现反面，当预测掷硬币出现的结果时，很不确定的判断掷硬币的结果。假设有一个非常不均匀的硬币，已知出现正面的概率为$\displaystyle \frac{8}{9}$，出现反面的概率为$\displaystyle \frac{1}{9}$，这个时候，正面出现的概率占了绝对的优势，此时预测掷硬币的结果，很有信心确定本次结果是正面，表明该信息没有那么混乱。

## 关系图说明
<br/><center>
<img style="border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="image/5-3-Entropy-Gini.png"><br><div style="color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #000;padding: 2px;">图5-3 二类分类中基尼指数、熵之半和分类误差率的关系</div></center>

&emsp;&emsp;如果把出现正面的概率记为$p$，观察图5-3，当$p=0$（掷硬币出现反面）或$p=1$（掷硬币出现正面）时，属于确定性事件，此时没有任何混乱，对应的基尼指数和熵之半都为0；随着$p$逐渐变大到0.5时，当前信息是最混乱的，对应的基尼指数和熵之半都为0.5；当$p$从0.5逐渐变大到1时，也就是出现正面的概率要超过0.5，并且越来越大，此时信息又逐渐不混乱，所以基尼指数和熵之半在减小。  
&emsp;&emsp;图中还出现了另一个指标：分类误差率，当$p=0.5$时，预测硬币出现是正面的事件概率为0.5，也就是说有50%的可能预测正确或错误；当出现正面的概率是0.3时，即$p=0.3$，此时肯定会预测硬币出现结果为反面，预测错误的概率为0.3，所以当$p=0.3$时，分类误差率为0.3；当$p=0.8$是，出现正面的概率是0.8，此时肯定会预测硬币出现结果为正面，预测错误的概率为0.2，所以当$p=0.8$时，分类误差率为0.2。